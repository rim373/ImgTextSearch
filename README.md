ImageSearchEngine
A Content-Based Image Retrieval (CBIR) system using VGG16 deep learning embeddings, Elasticsearch vector search, and FastAPI backend with HTML frontend.

ğŸ— Project Pipeline Overview
The project implements a visual similarity search pipeline using deep learning and vector embeddings:

Feature Extraction

Images are processed through VGG16 pre-trained CNN model.
Each image is converted into a 512-dimensional feature vector.
Vectors are L2-normalized for optimal cosine similarity computation.


Vector Storage & Indexing

Embeddings and metadata are indexed in Elasticsearch.
Uses dense_vector type with cosine similarity metric.
Supports fast similarity search across 800K+ images.


Similarity Computation

Cosine similarity measures angular distance between vectors.
Formula: cosine_similarity(A, B) = (A Â· B) / (||A|| Ã— ||B||)
Range: 0 to 1 (higher = more similar).
Offline: Vectors normalized during indexing.
Online: Query vector compared against indexed vectors using cosine similarity.


Backend API

Built with FastAPI.
Provides endpoints for:

Image upload and feature extraction
Cosine similarity-based search
Returning top-K similar images




Frontend

Built with Vanilla JS, HTML, and CSS.
Features:

Image upload interface
Visual display of similar images
Similarity scores display
Responsive layout






ğŸ“ Cosine Similarity in Action
Why Cosine Similarity?
âœ… Scale-invariant: Focuses on direction, not magnitude
âœ… Efficient: Optimized for high-dimensional spaces
âœ… Semantic: Better captures visual similarity than Euclidean distance
âœ… Native support: Elasticsearch optimizes cosine similarity queries
Offline vs Online
Offline (Indexing Phase):

Extract VGG16 features from all images
Normalize vectors using L2 normalization
Index normalized vectors in Elasticsearch
Elasticsearch configured with "similarity": "cosine"

Online (Search Phase):

User uploads query image
Extract and normalize VGG16 features
Elasticsearch computes cosine similarity between query vector and all indexed vectors
Return top-K images ranked by similarity score


ğŸ—‚ï¸ Project Structure
ImageSearchEngine/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                    # FastAPI backend (search API)
â”‚   â”œâ”€â”€ feature_extractor.py      # VGG16 feature extraction (512-D)
â”‚   â”œâ”€â”€ elasticsearch_utils.py    # ES operations with cosine similarity
â”‚   â”œâ”€â”€ index_images.py           # Offline indexing script
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ images/                   # Image dataset (800K+ images)
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html                # Web interface
â”‚
â””â”€â”€ README.md

âš™ï¸ Setup Instructions
Prerequisites

Python â‰¥ 3.8
Elasticsearch â‰¥ 8.x
pip or conda
Modern web browser


Step 1: Clone the Repository
bashgit clone https://github.com/yourusername/ImageSearchEngine.git
cd ImageSearchEngine

Step 2: Install Python Dependencies
bashcd backend
pip install -r requirements.txt
Key dependencies:

fastapi - Web framework
uvicorn - ASGI server
elasticsearch - ES client
torch / torchvision - VGG16 model
pillow - Image processing
numpy - Vector operations


Step 3: Install and Start Elasticsearch
Download Elasticsearch
bash# Download from: https://www.elastic.co/downloads/elasticsearch
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.x.x-linux-x86_64.tar.gz
tar -xzf elasticsearch-8.x.x-linux-x86_64.tar.gz
cd elasticsearch-8.x.x/
Start Elasticsearch
bashcd bin
./elasticsearch              # Linux/Mac
# or
elasticsearch.bat            # Windows
Elasticsearch runs at: http://localhost:9200
Verify Connection
bashcurl -X GET "http://localhost:9200/"
You should see a JSON response with cluster info.

Step 4: Configure Elasticsearch Index
The index is automatically created with cosine similarity configuration:
json{
  "mappings": {
    "properties": {
      "id": { "type": "keyword" },
      "path": { "type": "keyword" },
      "tags": { "type": "text" },
      "embedding": { 
        "type": "dense_vector", 
        "dims": 512,
        "similarity": "cosine"
      }
    }
  }
}
Important: "similarity": "cosine" enables optimized cosine similarity search in Elasticsearch.

Step 5: Index Your Images (Offline Phase)
Place your images in the data/images/ directory, then run:
bashcd backend
python index_images.py
What happens:

Loads each image from data/images/
Extracts 512-D VGG16 features from fc2 layer
Applies L2 normalization: normalized = vector / ||vector||
Creates document with metadata and normalized embedding
Bulk indexes into Elasticsearch

Example indexed document:
json{
  "id": "image_000123",
  "path": "data/images/image_000123.jpg",
  "tags": ["car", "road", "vehicle"],
  "embedding": [0.0123, 0.0456, ..., 0.0012]
}
Processing time: ~0.5-1s per image (depends on hardware)
âœ… After indexing completes, 800K+ images ready for cosine similarity search.

Step 6: Start the Backend Server
bashcd backend
uvicorn app:app --reload --host 0.0.0.0 --port 8000
API available at: http://localhost:8000
Swagger documentation: http://localhost:8000/docs

Step 7: Open the Frontend
Open frontend/index.html in your browser, or serve it:
bashcd frontend
python -m http.server 3000
Then navigate to: http://localhost:3000

ğŸ” API Endpoints
POST /search/image
Upload an image and search for visually similar images using cosine similarity.
Request:
bashcurl -X POST "http://localhost:8000/search/image" \
  -F "file=@query_image.jpg" \
  -F "top_k=10"
Response:
json{
  "query_id": "query_12345",
  "results": [
    {
      "id": "image_4521",
      "path": "data/images/image_4521.jpg",
      "score": 0.956,
      "tags": ["road", "car", "urban"]
    },
    {
      "id": "image_8902",
      "path": "data/images/image_8902.jpg",
      "score": 0.943,
      "tags": ["vehicle", "traffic", "highway"]
    }
  ]
}
Score interpretation:

0.95 - 1.0 = Very similar (near-duplicate or same scene)
0.85 - 0.95 = Similar visual content
0.70 - 0.85 = Related features
< 0.70 = Different content


ğŸš€ Usage Workflow
bash# 1. Start Elasticsearch
cd elasticsearch-8.x.x/bin
./elasticsearch

# 2. Index images (one-time setup)
cd backend
python index_images.py

# 3. Start FastAPI server
uvicorn app:app --reload

# 4. Open frontend
open frontend/index.html
Then:

Upload a query image via the web interface
System extracts VGG16 features and normalizes them
Elasticsearch computes cosine similarity with all indexed vectors
Top-K most similar images are returned and displayed
View results with similarity scores


ğŸ“Š Performance Metrics
MetricValueDataset Size800,000+ imagesEmbedding Dimensions512 (VGG16 fc2 layer)Similarity MetricCosine similarityNormalizationL2 normalizationSearch Latency< 100ms per queryIndexing Speed~1-2 images/secondIndex Storage~2 MB per 1,000 imagesMemory Usage~4GB for 800K vectors
Scalability:

Elasticsearch handles millions of vectors efficiently
HNSW algorithm optimizes approximate nearest neighbor search
Cosine similarity computed using optimized dot product on normalized vectors
Batch indexing recommended for large datasets


ğŸ§© Technology Stack
ComponentTechnologyPurposeFeature ExtractionVGG16 (PyTorch)Extract 512-D visual embeddingsVector DatabaseElasticsearch 8.xStore and search vectors with cosine similaritySimilarity MetricCosine SimilarityMeasure angular distance between embeddingsBackend FrameworkFastAPIREST API for search operationsFrontendHTML + Vanilla JS + CSSUser interface for image upload/resultsData FormatJSONDocument structure in ElasticsearchNormalizationL2 NormalizationPrepare vectors for cosine similarity

ğŸ§  Technical Deep Dive
VGG16 Feature Extraction
python# Pseudocode
model = VGG16(pretrained=True)
model = model.features  # Remove classification layer
model.eval()

def extract_features(image):
    # Preprocess
    img = resize(image, (224, 224))
    img = normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    
    # Extract
    features = model(img)  # Shape: (512,)
    
    # Normalize for cosine similarity
    features = features / np.linalg.norm(features)  # L2 normalization
    
    return features
Cosine Similarity Computation
python# Offline indexing
for image in dataset:
    vector = extract_features(image)
    vector = normalize_l2(vector)  # Important!
    elasticsearch.index(vector)

# Online search
query_vector = extract_features(query_image)
query_vector = normalize_l2(query_vector)

# Elasticsearch internally computes:
# score = dot_product(query_vector, indexed_vector)
# Because both vectors are L2-normalized, this equals cosine similarity
Why normalization matters:

Cosine similarity = dot product of normalized vectors
cos(Î¸) = (AÂ·B) / (||A|| Ã— ||B||)
If ||A|| = 1 and ||B|| = 1, then cos(Î¸) = AÂ·B
This makes computation faster and more efficient


ğŸ”§ Configuration Options
Elasticsearch Settings
Edit elasticsearch_utils.py:
pythonINDEX_SETTINGS = {
    "settings": {
        "number_of_shards": 3,
        "number_of_replicas": 1,
        "index.knn": True  # Enable k-NN search
    },
    "mappings": {
        "properties": {
            "embedding": {
                "type": "dense_vector",
                "dims": 512,
                "similarity": "cosine",  # Can also use: "dot_product", "l2_norm"
                "index": True,
                "index_options": {
                    "type": "hnsw",
                    "m": 16,
                    "ef_construction": 100
                }
            }
        }
    }
}
Search Parameters
python# In app.py
TOP_K = 10  # Number of results to return
MIN_SCORE = 0.7  # Minimum similarity threshold

ğŸ”¬ Future Enhancements

 Multi-modal search: CLIP embeddings for text-to-image search
 Advanced models: ResNet, EfficientNet, Vision Transformers
 Alternative vector DBs: FAISS, Milvus, Pinecone for billion-scale
 Batch upload: Bulk image upload via API
 Auto-tagging: Automatic label generation using CNNs
 Hybrid search: Combine text metadata + visual similarity
 GPU acceleration: Batch feature extraction on GPU
 Query expansion: Use multiple query images
 Relevance feedback: Learn from user interactions
 Docker deployment: Containerized setup


ğŸ“š References

VGG16 Paper: Very Deep Convolutional Networks for Large-Scale Image Recognition
Elasticsearch Vector Search: Dense Vector Field Type
Cosine Similarity: Understanding Cosine Similarity
CBIR Systems: Content-Based Image Retrieval


ğŸ‘©â€ğŸ’» Author
Rim Barnat
AI & Telecommunications Researcher
ğŸ“š Specialized in Deep Learning, Computer Vision, and Retrieval-Augmented Generation systems.

ğŸ“„ License
MIT License - feel free to use and modify for your projects.

ğŸ™ Acknowledgments

VGG Team at University of Oxford for the VGG16 architecture
Elasticsearch team for powerful vector search capabilities
PyTorch community for deep learning framework
FastAPI for modern Python web framework


ğŸ“ Support
For questions or issues:

Open an issue on GitHub
Email: [your-email@example.com]
LinkedIn: [Your LinkedIn Profile]


ğŸ’¡ This project demonstrates production-ready content-based image retrieval using deep learning embeddings, cosine similarity matching, and scalable vector search infrastructure.
